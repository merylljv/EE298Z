{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection\n",
    "\n",
    "## Background\n",
    "\n",
    "The [ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/overview) is a competition hosted by kaggle for  [IEEE Computational Intelligence Society (IEEE-CIS)](https://cis.ieee.org/). The challenge requires participants to predict the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The [data](https://www.kaggle.com/c/14242/download-all) is broken into two files: identity and transaction, which are joined by TransactionID; not all transactions have corresponding identity information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TbN9UXMEzyJ"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y44uBDeaE5eE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42) # NumPy\n",
    "random.seed(42) # Python\n",
    "tf.set_random_seed(42) # Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYZu6LjdHZeQ"
   },
   "source": [
    "### Data Loading and Preprocessing\n",
    "\n",
    "After a brief investigation there isn't any significant improvement by using all features; hence, only the features from transaction table were used. The transaction data has categorical and numerical features: \n",
    "\n",
    "- for numerical features: \n",
    "    - log-transform was applied to skewed data to make it normally distributed\n",
    "    - standardization was applied to make the training process well behaved because the numerical condition of the optimization problems is improved.\n",
    "- for categorical features: \n",
    "    - OneHot transformation using only the top 50 categories per feature to reduce sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataproc\n",
    "X_tr, X_val, X_test, y_tr, y_val, sub = dataproc.main(upsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJ5_AqRJ6wWg"
   },
   "source": [
    "### Modeling\n",
    "\n",
    "Focal loss and binary cross entropy were used as loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 235279,
     "status": "ok",
     "timestamp": 1571194095858,
     "user": {
      "displayName": "merylljv08",
      "photoUrl": "",
      "userId": "02176225216062102750"
     },
     "user_tz": -480
    },
    "id": "FdLXAM_06wWi",
    "outputId": "0ce6a38b-6881-404c-80f3-ae7a77ea6e0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1018 19:18:35.128804  3664 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compatible with tensorflow backend\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc_val: %s' % (str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "    \n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.mean((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def custom_gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "\n",
    "get_custom_objects().update({'custom_gelu': Activation(custom_gelu)})\n",
    "get_custom_objects().update({'focal_loss_fn': focal_loss()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained by CNN layers, the network is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWtq8myh6wWk"
   },
   "outputs": [],
   "source": [
    "def create_model(loss_fn):\n",
    "    inps = Input(shape=(X_tr.shape[1],))\n",
    "    x = Dense(512, activation=custom_gelu)(inps)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation=custom_gelu)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inps, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=Nadam(),\n",
    "        loss=[loss_fn]\n",
    "    )\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='cnn-cifar10.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 235911,
     "status": "ok",
     "timestamp": 1571194096500,
     "user": {
      "displayName": "merylljv08",
      "photoUrl": "",
      "userId": "02176225216062102750"
     },
     "user_tz": -480
    },
    "id": "Wy6oWgNK6wWm",
    "outputId": "533da30f-cfa3-4770-d62e-3ce1b53247bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 19:18:35.176815  3664 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1018 19:18:35.308843  3664 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1018 19:18:35.620914  3664 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1018 19:18:35.684931  3664 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1018 19:18:36.045011  3664 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1018 19:18:36.065019  3664 deprecation.py:323] From <ipython-input-3-69d84efadb93>:33: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1018 19:18:36.089025  3664 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 504)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               258560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 393,217\n",
      "Trainable params: 391,681\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 504)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               258560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 393,217\n",
      "Trainable params: 391,681\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_focal = create_model('focal_loss_fn')\n",
    "model_bce = create_model('binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 521235,
     "status": "ok",
     "timestamp": 1571194381831,
     "user": {
      "displayName": "merylljv08",
      "photoUrl": "",
      "userId": "02176225216062102750"
     },
     "user_tz": -480
    },
    "id": "doZOPx3r6wWo",
    "outputId": "ed154b05-1145-406c-84ef-37b1ffdb864f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 912022 samples, validate on 118108 samples\n",
      "Epoch 1/8\n",
      "912022/912022 [==============================] - 117s 128us/step - loss: 0.2485 - val_loss: 0.7302\n",
      "roc-auc_val: 0.9367                                                                                                    \n",
      "Epoch 2/8\n",
      "912022/912022 [==============================] - 113s 123us/step - loss: 0.1138 - val_loss: 0.1194\n",
      "roc-auc_val: 0.9532                                                                                                    \n",
      "Epoch 3/8\n",
      "912022/912022 [==============================] - 112s 123us/step - loss: 0.0824 - val_loss: 0.1065\n",
      "roc-auc_val: 0.9565                                                                                                    \n",
      "Epoch 4/8\n",
      "912022/912022 [==============================] - 111s 122us/step - loss: 0.0671 - val_loss: 0.0875\n",
      "roc-auc_val: 0.9565                                                                                                    \n",
      "Epoch 5/8\n",
      "912022/912022 [==============================] - 111s 122us/step - loss: 0.0587 - val_loss: 0.0970\n",
      "roc-auc_val: 0.9592                                                                                                    \n",
      "Epoch 6/8\n",
      "912022/912022 [==============================] - 111s 122us/step - loss: 0.0524 - val_loss: 0.1056\n",
      "roc-auc_val: 0.9618                                                                                                    \n",
      "Epoch 7/8\n",
      "912022/912022 [==============================] - 111s 121us/step - loss: 0.0489 - val_loss: 0.1055\n",
      "roc-auc_val: 0.9599                                                                                                    \n",
      "Epoch 8/8\n",
      "912022/912022 [==============================] - 110s 121us/step - loss: 0.0452 - val_loss: 0.0911\n",
      "roc-auc_val: 0.9581                                                                                                    \n",
      "Train on 912022 samples, validate on 118108 samples\n",
      "Epoch 1/8\n",
      "912022/912022 [==============================] - 116s 127us/step - loss: 0.0368 - val_loss: 0.1468\n",
      "roc-auc_val: 0.929                                                                                                    \n",
      "Epoch 2/8\n",
      "912022/912022 [==============================] - 117s 128us/step - loss: 0.0176 - val_loss: 0.0320\n",
      "roc-auc_val: 0.9446                                                                                                    \n",
      "Epoch 3/8\n",
      "912022/912022 [==============================] - 122s 133us/step - loss: 0.0123 - val_loss: 0.0162\n",
      "roc-auc_val: 0.9548                                                                                                    \n",
      "Epoch 4/8\n",
      "912022/912022 [==============================] - 125s 137us/step - loss: 0.0098 - val_loss: 0.0131\n",
      "roc-auc_val: 0.9526                                                                                                    \n",
      "Epoch 5/8\n",
      "912022/912022 [==============================] - 114s 125us/step - loss: 0.0083 - val_loss: 0.0116\n",
      "roc-auc_val: 0.954                                                                                                    \n",
      "Epoch 6/8\n",
      "912022/912022 [==============================] - 113s 124us/step - loss: 0.0074 - val_loss: 0.0127\n",
      "roc-auc_val: 0.9569                                                                                                    \n",
      "Epoch 7/8\n",
      "912022/912022 [==============================] - 116s 127us/step - loss: 0.0068 - val_loss: 0.0118\n",
      "roc-auc_val: 0.9574                                                                                                    \n",
      "Epoch 8/8\n",
      "912022/912022 [==============================] - 115s 126us/step - loss: 0.0063 - val_loss: 0.0149\n",
      "roc-auc_val: 0.958                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ad78e45f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bce.fit(\n",
    "    X_tr, y_tr, epochs=8, batch_size=2048, validation_data=(X_val, y_val), verbose=True, \n",
    "    callbacks=[roc_callback(training_data=(X_val, y_tr), validation_data=(X_val, y_val))]\n",
    ")\n",
    "model_focal.fit(\n",
    "    X_tr, y_tr, epochs=8, batch_size=2048, validation_data=(X_val, y_val), verbose=True, \n",
    "    callbacks=[roc_callback(training_data=(X_val, y_tr), validation_data=(X_val, y_val))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c86R60J56wWq"
   },
   "outputs": [],
   "source": [
    "val_preds_bce = model_bce.predict(X_val).flatten()\n",
    "val_preds_focal = model_focal.predict(X_val).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same model with different loss functions used were ensembled using averaging appeared to have higher scores; even higher when using rankdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 533168,
     "status": "ok",
     "timestamp": 1571194393775,
     "user": {
      "displayName": "merylljv08",
      "photoUrl": "",
      "userId": "02176225216062102750"
     },
     "user_tz": -480
    },
    "id": "rlVB1Ihr6wWr",
    "outputId": "f7a5da1c-91ec-43d6-8e20-fbd0ce268cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE preds:  0.9580845100827509\n",
      "Focal preds:  0.9580170076420838\n",
      "Averaging:  0.961566422819819\n",
      "Rank averaging:  0.9624829550385177\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata, spearmanr\n",
    "\n",
    "print('BCE preds: ', roc_auc_score(y_val, val_preds_bce))\n",
    "print('Focal preds: ',roc_auc_score(y_val, val_preds_focal))\n",
    "print('Averaging: ', roc_auc_score(y_val, val_preds_bce + val_preds_focal))\n",
    "print('Rank averaging: ', roc_auc_score(y_val, rankdata(val_preds_bce, method='dense') + rankdata(val_preds_focal, method='dense')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPupKSUa6wWv"
   },
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fhBX4wN6wWz"
   },
   "outputs": [],
   "source": [
    "sub = sub.reset_index()\n",
    "sub.loc[:, 'TransactionID'] = sub.loc[:, 'TransactionID'].astype(int)\n",
    "sub.loc[:, 'isFraud'] = rankdata(model_bce.predict(X_test).flatten(), method='dense') + rankdata(model_focal.predict(X_test).flatten(), method='dense')\n",
    "sub.loc[:, 'isFraud'] = sub.loc[:, 'isFraud']/sub.loc[:, 'isFraud'].max()\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KerasNN_fraud_detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
