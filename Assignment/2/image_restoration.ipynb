{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d956f157de27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "(X_train, _), (X_test, _) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a simple autoencoder based on a fully connected layers. One hidden layer handles the encoding, and the output layer handles the decoding.\n",
    "Each of the input images is flatten to an array of 784 (=28×28) data points. This is then compressed into 32 data points by the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = Input(shape=(784,))           # 28*28 flatten\n",
    "enc_fc  = Dense( 32, activation='relu') # to 32 data points\n",
    "encoded = enc_fc(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we decode the encoded data to the original 784 data points. The sigmoid will return values between 0 and 1 for each pixel (intensity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_fc  = Dense(784, activation='sigmoid') # to 784 data points\n",
    "decoded = dec_fc(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole processing becomes the trainable autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the MNIST image data so that image data are normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = x.astype('float32') / 255.\n",
    "    return x.reshape(-1, np.prod(x.shape[1:])) # flatten\n",
    "X_train = preprocess(X_train)\n",
    "X_test  = preprocess(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also split the train data into a train set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_test_split(X_train, test_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the autoencoder which compress the input image and then restore to the original size. As such, our training data and label data are both the same image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train, X_train, # data and label are the same\n",
    "                epochs=50, \n",
    "                batch_size=128, \n",
    "                validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By training an autoencoder, we are really training both the encoder and the decoder at the same time.\n",
    "We can build an encoder and use it to compress MNIST digit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs, encoded)\n",
    "X_test_encoded = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also build a decoder so that we can decompress the compressed image to the original image size. The decoder takes 32 data points as its input (the size of encoded data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(32,))\n",
    "decoder = Model(decoder_inputs, dec_fc(decoder_inputs))\n",
    "# decode the encoded test data\n",
    "X_test_decoded = decoder.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_convolutional_autoencoder():\n",
    "    # encoding\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D(padding='same')(x)    \n",
    "    \n",
    "    # decoding\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(16, 3, activation='relu')(x) # <= padding='valid'!\n",
    "    x = UpSampling2D()(x)\n",
    "    decoded = Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    # autoencoder\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', \n",
    "                        loss='binary_crossentropy')\n",
    "    return autoencoder\n",
    "# create a convolutional autoencoder\n",
    "autoencoder = make_convolutional_autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we reshape the image data to the format the convolutional autoencoder expects for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the flattened images to 28x28 with 1 channel\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_valid = X_valid.reshape(-1, 28, 28, 1)\n",
    "X_test  = X_test.reshape(-1, 28, 28, 1)\n",
    "autoencoder.fit(X_train, X_train, \n",
    "                epochs=50, \n",
    "                batch_size=128, \n",
    "                validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just want to see the quality of compression/decompression, for which we do not need to build separate encoder and decoder models. So, we simply feed forward test images to see how the restored digits look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_decoded = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x, noise_factor=0.2):\n",
    "    x = x + np.random.randn(*x.shape) * noise_factor\n",
    "    x = x.clip(0., 1.)\n",
    "    return x\n",
    "    \n",
    "X_train_noisy = add_noise(X_train)\n",
    "X_valid_noisy = add_noise(X_valid)\n",
    "X_test_noisy  = add_noise(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a new autoencoder with the noisy data as input and the original data as expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = make_convolutional_autoencoder()\n",
    "autoencoder.fit(X_train_noisy, X_train, \n",
    "                epochs=50, \n",
    "                batch_size=128, \n",
    "                validation_data=(X_valid_noisy, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training, the autoencoder learns to extract important features from input images and ignores the image noises because the labels have no noises.\n",
    "Let’s pass the noisy test images to the autoencoder to see the restored images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_decoded = autoencoder.predict(X_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
